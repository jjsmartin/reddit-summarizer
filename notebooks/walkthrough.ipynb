{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib \n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from pydantic.v1 import BaseModel, Field \n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.output_parsers import PydanticOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API key from .env file\n",
    "import dotenv \n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get some posts from a subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDIT = \"todayilearned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can put \".json\" at the end of any subreddit URL to get recent posts in JSON format\n",
    "# We don't get comments here, but we can apply the same approach to an individual post URL to get them.\n",
    "with urllib.request.urlopen(f\"https://www.reddit.com/r/{SUBREDDIT}.json\") as url:\n",
    "    data = json.loads(url.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reddit.com/r/todayilearned/comments/1969o7i/til_about_the_crazy_horse_memorial_the_worlds/'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permalink = \"/r/todayilearned/comments/1969o7i/til_about_the_crazy_horse_memorial_the_worlds/\"\n",
    "permalink_url = f\"https://www.reddit.com{permalink}\"\n",
    "comments_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are lots of fields for each post, we'll just take these ones\n",
    "required_keys = [\"permalink\", \"title\", \"created_utc\", \"num_comments\", \"score\", \"selftext\"]\n",
    "\n",
    "posts = []\n",
    "for post in data[\"data\"][\"children\"]:\n",
    "    post_data = post[\"data\"]\n",
    "    post_data = {k: post_data[k] for k in required_keys}\n",
    "    posts.append(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'permalink': '/r/todayilearned/comments/195yrit/til_new_yorks_paramount_theater_would_reek_of/',\n",
       " 'title': \"TIL New York's Paramount theater would reek of urine after Frank Sinatra shows because the bobby-soxers would come for the first show at 9:15 a.m. and stay for show after show, determined never to relinquish a precious seat even if it meant soaking in it.\",\n",
       " 'created_utc': 1705181511.0,\n",
       " 'num_comments': 692,\n",
       " 'score': 16535,\n",
       " 'selftext': ''}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at this point, the data looks like this\n",
    "posts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a template for parsing each post\n",
    "\n",
    "We want to send the LLM the posts to summarize plus some instructions about what to do. We also want to get the instructions back in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can edit the text here to give the LLM more context about what we're interested in.\n",
    "template_string = \"\"\" \n",
    "\n",
    "This is a post from the subreddit {subreddit}:\n",
    "\n",
    "{post}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add a custom series of fields here to give the LLM more guidance on what we're interested in. \n",
    "# We specify whether each field is freeform text, a true/false flag or whatever else.\n",
    "class Post(BaseModel):\n",
    "    summary: str = Field(description=\"A short summary of what the post is about. You don't need to explain that it is a reddit post.\", max_length=1000)\n",
    "    sport: bool = Field(description=\"Is this post about sport?\")\n",
    "    entertainment: bool = Field(description=\"Is this post about entertainment?\")\n",
    "    politics: bool = Field(description=\"Is this post about politics?\")\n",
    "    science: bool = Field(description=\"Is this post about science?\")\n",
    "    history: bool = Field(description=\"Is this post about history?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = PydanticOutputParser(pydantic_object=Post)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send the prompts to the LLM\n",
    "\n",
    "We'll use ChatGPT 4 here, but it's easy to swap in different models with Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [({\n",
    "    \"subreddit\": SUBREDDIT,\n",
    "    \"post\": post, \n",
    "    \"format_instructions\": format_instructions}) for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chain.batch(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Put all the relevant parts into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As far as I can tell, the order of the batched results is the same as the order of the inputs, but I'm not sure if this is guaranteed.\n",
    "results_df = pd.DataFrame(dict(r) for r in results)\n",
    "posts_df = pd.DataFrame(posts)\n",
    "\n",
    "reddit = (\n",
    "    pd.concat([results_df, posts_df], axis=1)\n",
    "    .assign(\n",
    "        post_datetime = lambda df: pd.to_datetime(df.created_utc.astype('int'), utc=True, unit='s').dt.tz_localize(None),  # remove timezone\n",
    "        scraped_datetime = datetime.today()\n",
    "    )\n",
    "    .assign(\n",
    "        # convenient to create a full url for each post\n",
    "        link = lambda df: df['permalink'].apply(lambda x: f\"https://www.reddit.com{x}\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>sport</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>politics</th>\n",
       "      <th>science</th>\n",
       "      <th>history</th>\n",
       "      <th>permalink</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>post_datetime</th>\n",
       "      <th>scraped_datetime</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sumo wrestlers, despite eating 10,000+ calorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/todayilearned/comments/195o141/til_that_sum...</td>\n",
       "      <td>TIL that sumo wrestlers, despite eating 10,000...</td>\n",
       "      <td>1.705153e+09</td>\n",
       "      <td>920</td>\n",
       "      <td>15683</td>\n",
       "      <td></td>\n",
       "      <td>2024-01-13 13:29:29</td>\n",
       "      <td>2024-01-14 13:06:27.898256</td>\n",
       "      <td>https://www.reddit.com/r/todayilearned/comment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TIL Steve Young, 3x NFL Super Bowl Champion, i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/r/todayilearned/comments/195x26i/til_steve_yo...</td>\n",
       "      <td>TIL Steve Young, 3x NFL Super Bowl Champion, i...</td>\n",
       "      <td>1.705177e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>428</td>\n",
       "      <td></td>\n",
       "      <td>2024-01-13 20:16:33</td>\n",
       "      <td>2024-01-14 13:06:27.898256</td>\n",
       "      <td>https://www.reddit.com/r/todayilearned/comment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The French developed Canne de combat, a cane f...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/r/todayilearned/comments/195tzjx/til_the_fren...</td>\n",
       "      <td>TIL: The French in the 19th century developed ...</td>\n",
       "      <td>1.705169e+09</td>\n",
       "      <td>35</td>\n",
       "      <td>599</td>\n",
       "      <td></td>\n",
       "      <td>2024-01-13 18:04:46</td>\n",
       "      <td>2024-01-14 13:06:27.898256</td>\n",
       "      <td>https://www.reddit.com/r/todayilearned/comment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              summary  sport  entertainment  \\\n",
       "7   Sumo wrestlers, despite eating 10,000+ calorie...   True          False   \n",
       "22  TIL Steve Young, 3x NFL Super Bowl Champion, i...   True          False   \n",
       "23  The French developed Canne de combat, a cane f...   True          False   \n",
       "\n",
       "    politics  science  history  \\\n",
       "7      False     True    False   \n",
       "22     False    False     True   \n",
       "23     False    False     True   \n",
       "\n",
       "                                            permalink  \\\n",
       "7   /r/todayilearned/comments/195o141/til_that_sum...   \n",
       "22  /r/todayilearned/comments/195x26i/til_steve_yo...   \n",
       "23  /r/todayilearned/comments/195tzjx/til_the_fren...   \n",
       "\n",
       "                                                title   created_utc  \\\n",
       "7   TIL that sumo wrestlers, despite eating 10,000...  1.705153e+09   \n",
       "22  TIL Steve Young, 3x NFL Super Bowl Champion, i...  1.705177e+09   \n",
       "23  TIL: The French in the 19th century developed ...  1.705169e+09   \n",
       "\n",
       "    num_comments  score selftext       post_datetime  \\\n",
       "7            920  15683          2024-01-13 13:29:29   \n",
       "22            37    428          2024-01-13 20:16:33   \n",
       "23            35    599          2024-01-13 18:04:46   \n",
       "\n",
       "             scraped_datetime  \\\n",
       "7  2024-01-14 13:06:27.898256   \n",
       "22 2024-01-14 13:06:27.898256   \n",
       "23 2024-01-14 13:06:27.898256   \n",
       "\n",
       "                                                 link  \n",
       "7   https://www.reddit.com/r/todayilearned/comment...  \n",
       "22  https://www.reddit.com/r/todayilearned/comment...  \n",
       "23  https://www.reddit.com/r/todayilearned/comment...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect a particular category\n",
    "reddit.query(\"sport == True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "\n",
    "Write to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns in the data frame: various identifiers plus the things we asked for in the prompt\n",
    "cols = ['link', 'title', 'post_datetime'] + list(Post.__fields__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_suffix = datetime.today().strftime(\"%Y%m%d\")\n",
    "reddit[cols].to_csv(f\"../output/{SUBREDDIT}_{date_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
